---
train_folder: /mnt/mldata2/iren_tmp/domen_class/dataset_tiles_512/train
val_folder: /mnt/mldata2/iren_tmp/domen_class/dataset_tiles_512/val
logs_folder: /mnt/mldata2/iren_tmp/pl_dataset/logs/


monitor_metric: val_acc
img_size: 512
inference_batch: 4

img_loader:
  description:
    type: helpers.img_loader.ImageLoader.cv2_loader

batch_size: 1

model:
  description:
    type: efficientnet_pytorch.EfficientNet.from_pretrained
    model_name: efficientnet-b5
  classes: 3

optimizer:
  type: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.0001

scheduler:
  type: torch.optim.lr_scheduler.StepLR
  step_size: 2
  gamma: 0.1

train_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fullname__: albumentations.augmentations.transforms.PadIfNeeded
        min_height: 512
        min_width: 512
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.RandomResizedCrop
        height: 512
        width: 512
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.Transpose
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.HorizontalFlip
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.VerticalFlip
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.ShiftScaleRotate
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.HueSaturationValue
        hue_shift_limit: 0.2
        sat_shift_limit: 0.2
        val_shift_limit: 0.2
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.RandomBrightnessContrast
        brightness_limit:
          - -0.1
          - 0.1
        contrast_limit:
          - -0.1
          - 0.1
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225
      - __class_fullname__: albumentations.augmentations.transforms.CoarseDropout
        p: 0.5
      - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
        p: 1.0


val_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225
      - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
        p: 1.0

test_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225
      - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
        p: 1.0